{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8NOsYECIStf",
        "outputId": "4c1b702e-4855-4e6e-a4f1-e8c8681ae47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UnsupportedWavFileException(Exception):\n",
        "  \"Unsupported WAV File\""
      ],
      "metadata": {
        "id": "UZKnaOLTIU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def load_spectrograms(dirs, winsize=2048, hopsize=None):\n",
        "    x_all = []\n",
        "    sr_all = []\n",
        "    S_all = []\n",
        "    if hopsize is None:\n",
        "        hopsize = int(winsize / 4)\n",
        "\n",
        "    for directory in dirs:\n",
        "        files = glob.glob(directory + \"/*.wav\")\n",
        "        for i, f in enumerate(files):\n",
        "            try:\n",
        "                y, sr = librosa.load(f)\n",
        "                sr_all.append(sr)\n",
        "                D = librosa.stft(y, n_fft=winsize, win_length=winsize, hop_length=hopsize)\n",
        "                S, phase = librosa.magphase(D)\n",
        "                x_all.append(np.expand_dims(S, axis=-1))\n",
        "                S_all.append(np.abs(D))\n",
        "                print(i, f, len(S_all) - 1)\n",
        "            except:\n",
        "                print(\"skip\")\n",
        "\n",
        "    x_train = np.asarray(x_all)\n",
        "    return x_train, sr_all, S_all"
      ],
      "metadata": {
        "id": "3jUbKn05IYYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirs =[\"/content/drive/MyDrive/B4川原/wav/Sound Pool/Vol.2/TechnoTrance Vol.9/Drums\"]\n",
        "\n",
        "x_train, sr_all, original_S = load_spectrograms(dirs)"
      ],
      "metadata": {
        "id": "i8vjuWemIaHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "encoded_dim=16\n",
        "tfd = tfp.distributions\n",
        "prior = tfd.Independent(\n",
        "tfd.Normal(loc=tf.zeros(encoded_dim), scale=1),\n",
        "reinterpreted_batch_ndims=1)"
      ],
      "metadata": {
        "id": "GNOxArbtIbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = x_train.shape[2]\n",
        "input_dim = x_train.shape[1]\n",
        "hidden_dim=256\n",
        "encoder = tf.keras.Sequential()\n",
        "encoder.add(tf.keras.layers.Conv2D(hidden_dim, (input_dim,1),\n",
        "                                   input_shape=(input_dim,seq_length, 1),\n",
        "                                   strides=1, padding=\"valid\",\n",
        "                                   activation=\"relu\"))\n",
        "encoder.add(tf.keras.layers.Conv2D(hidden_dim, (1,37), strides=( 1,37),\n",
        "                                   padding=\"valid\", activation=\"relu\"))\n",
        "encoder.add(tf.keras.layers.Conv2D(hidden_dim, (1,4), strides=(1,4),\n",
        "                                   padding=\"valid\", activation=\"relu\"))\n",
        "encoder.add(tf.keras.layers.Flatten())\n",
        "encoder.add(tf.keras.layers.Dense(\n",
        "    tfp.layers.MultivariateNormalTriL.params_size(encoded_dim),\n",
        "    activation=None))\n",
        "encoder.add(tfp.layers.MultivariateNormalTriL(\n",
        "    encoded_dim,\n",
        "    activity_regularizer=tfp.layers.KLDivergenceRegularizer(\n",
        "        prior, weight=0.001)))\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "lMaqBkVjIdLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = tf.keras.Sequential()\n",
        "decoder.add(tf.keras.layers.Dense(hidden_dim, input_dim=encoded_dim,\n",
        "                                  activation=\"relu\"))\n",
        "\n",
        "decoder.add(tf.keras.layers.Reshape((1, 1, hidden_dim)))\n",
        "decoder.add(tf.keras.layers.Conv2DTranspose( hidden_dim, (1,4), strides=(1,4), padding=\"valid\", activation=\"relu\"))\n",
        "decoder.add(tf.keras.layers.Conv2DTranspose( hidden_dim, (1,37), strides=(1,37), padding=\"valid\", activation=\"relu\"))\n",
        "decoder.add(tf.keras.layers.Conv2DTranspose( 1, (input_dim,1), strides=1, padding=\"valid\", activation=\"relu\"))\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "7AJQZuqeIevN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "os.makedirs('drive/MyDrive/vae_model', exist_ok=True)\n",
        "vae = tf.keras.Model(encoder.inputs, decoder(encoder.outputs))\n",
        "weight_path = '/content/drive/MyDrive/vae_model/model.h5'\n",
        "\n",
        "if os.path.exists(weight_path):\n",
        "    vae.load_weights(weight_path)\n",
        "vae.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mse\")\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join('drive/MyDrive/vae_model', 'model.h5'),\n",
        "    monitor='loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1)\n",
        "\n",
        "history = vae.fit(x_train, x_train, epochs=500, batch_size=16, callbacks=[model_checkpoint])"
      ],
      "metadata": {
        "id": "pLfSCi-bIglX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "os.makedirs('drive/MyDrive/vae_model', exist_ok=True)\n",
        "vae = tf.keras.Model(encoder.inputs, decoder(encoder.outputs))\n",
        "vae.load_weights('/content/drive/MyDrive/vae_model/model.h5')\n",
        "vae.compile(optimizer=\"adam\", loss=\"mse\", metrics=\"mse\")\n"
      ],
      "metadata": {
        "id": "U7S3qF26IiXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.evaluate(x_train,x_train)"
      ],
      "metadata": {
        "id": "_72jes3pIkJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = encoder.predict(x_train)"
      ],
      "metadata": {
        "id": "Oh8wXLlhIl4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_spectrograms(encoder, decoder, z):\n",
        "    re_spec = []\n",
        "    for i in range(len(z)):\n",
        "        try:\n",
        "            d = decoder.predict(np.array([z[i]]))\n",
        "            re_spec.append(np.squeeze(d))\n",
        "        except UnsupportedWavFileException:\n",
        "            print(\"Skip\")\n",
        "    return re_spec\n",
        "\n",
        "re_spec = decode_spectrograms(encoder, decoder, z)"
      ],
      "metadata": {
        "id": "jZOng5q-InL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = []\n",
        "for i in range(len(original_S)):\n",
        "    s1 = original_S[i]\n",
        "    s2 = re_spec[i]\n",
        "    cosine_similarity = np.dot(s1.flatten(), s2.flatten()) / (np.linalg.norm(s1) * np.linalg.norm(s2))\n",
        "    similarities.append(cosine_similarity)\n",
        "    print(i)\n",
        "    print(\"類似度: \", cosine_similarity)"
      ],
      "metadata": {
        "id": "J5jL9TWmIo-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "a = 0.5\n",
        "i = 指定した音源数字\n",
        "j = 指定した音源数字\n",
        "my_x = decoder.predict(np.array([z[i]])*a + np.array([z[j]])* (1-a))\n",
        "my_x = np.squeeze(my_x)"
      ],
      "metadata": {
        "id": "mP25ygSrIrRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "winsize = 2048\n",
        "hopsize = int(winsize/4)\n",
        "y_inv = librosa.griffinlim(my_x, n_iter=32, win_length=winsize, hop_length=hopsize)\n",
        "print(y_inv)\n",
        "plt.matshow(my_x)"
      ],
      "metadata": {
        "id": "W6_HOM-jItPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.display(IPython.display.Audio(y_inv, rate=sr_all[0]))"
      ],
      "metadata": {
        "id": "kBb-ymyqIu30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}